models:
  mistral:
    name: "Mistral"
    version: "latest"
    description: "Fast and efficient model"
    context_window: 32000
    max_tokens: 8000
    default_temperature: 0.7
    default_top_p: 0.9
    capabilities:
      - "text_generation"
      - "code_generation"
      - "reasoning"
    cost_per_1k_tokens: 0.0001

  llama3.2:
    name: "Llama 3.2"
    version: "latest"
    description: "Powerful open-source model"
    context_window: 8192
    max_tokens: 4096
    default_temperature: 0.7
    default_top_p: 0.9
    capabilities:
      - "text_generation"
      - "instruction_following"
      - "reasoning"
    cost_per_1k_tokens: 0.00005

  deepseek-r1:
    name: "DeepSeek R1"
    version: "latest"
    description: "Advanced reasoning model"
    context_window: 64000
    max_tokens: 8000
    default_temperature: 0.5
    default_top_p: 0.9
    capabilities:
      - "reasoning"
      - "problem_solving"
      - "analysis"
    cost_per_1k_tokens: 0.0002

  phi4-mini:
    name: "Phi 4 Mini"
    version: "latest"
    description: "Lightweight efficient model"
    context_window: 4096
    max_tokens: 2048
    default_temperature: 0.7
    default_top_p: 0.9
    capabilities:
      - "text_generation"
      - "summarization"
      - "classification"
    cost_per_1k_tokens: 0.00001

defaults:
  temperature: 0.7
  top_p: 0.9
  top_k: 40
  max_tokens: 2000
  frequency_penalty: 0.0
  presence_penalty: 0.0

prompts:
  system_prompt: "You are a helpful AI assistant specialized in business requirements documentation."
  classification_prompt: "Classify the following text into one of these categories: {categories}"
  summarization_prompt: "Summarize the following text concisely:\n{text}"
  analysis_prompt: "Analyze the following content and provide insights:\n{content}"

safety:
  enable_content_filtering: true
  block_unsafe_content: true
  harmful_content_threshold: 0.7
  
fallback:
  enabled: true
  fallback_model: "mistral"
  retry_attempts: 3
  retry_delay_seconds: 1

rate_limiting:
  enabled: true
  requests_per_minute: 60
  requests_per_hour: 1000
  tokens_per_minute: 90000
